# Example of process-chains for extracting BRK source data from zipped GML archives to PostGIS.
# A Chain is a series of Components: one Input, zero or more Filters and one Output.
# The output of a Component is connected to the input of the next Component (except for
# the final Output Component, which writes to the final destination, e.g. Postgres.
#
# Currently 2 chains are executed in the following order:
# 1 - SQL pre:  DB initialization, delete tables, create schema
# 2 - Main ETL chain, consists of the following components
# a. input_zip_file: read input ZIP files and output records with names of files found in ZIP
# b. extract_zip_file: extract one file from a zip into a temp dir
# c. output_ogr2ogr: output using ogr2ogr, input is the GML file (step 2), output can be any OGR output
#
# Any substitutable values are specified in curly brackets e.g. {password}.
# Actual values can be passed as args to Stetl main.py or as arguments from a wrapper program.

[etl]
chains = input_sql_pre|schema_name_filter|output_postgres,
         input_zip_file|extract_zip_file|output_ogr2ogr,
         input_sql_post|schema_name_filter|output_postgres

# Alternative chains for testing
#chains = input_zip_file|extract_zip_file|output_std

# Pre SQL file inputs to be executed
[input_sql_pre]
class = inputs.fileinput.StringFileInput
file_path = sql/drop-tables.sql,sql/create-schema.sql

# Post SQL file inputs to be executed
[input_sql_post]
class = inputs.fileinput.StringFileInput
file_path = sql/delete-duplicates.sql

# Generic filter to substitute Python-format string values like {schema} in string
[schema_name_filter]
class = filters.stringfilter.StringSubstitutionFilter
# format args {schema} is schema name
format_args = schema:{schema}

[output_postgres]
class = outputs.dboutput.PostgresDbOutput
database = {database}
host = {host}
port = {port}
user = {user}
password = {password}
schema = {schema}

# The source input ZIP-file(s) from dir, producing 'records' with ZIP file name and inner file names
[input_zip_file]
class=inputs.fileinput.ZipFileInput
file_path = {input_dir}
filename_pattern = {zip_files_pattern}
name_filter = {filename_match}

# Filter to extract a ZIP file one by one to a temporary location
[extract_zip_file]
class=filters.zipfileextractor.ZipFileExtractor
file_path = {temp_dir}/fromzip-tmp.gml

# The ogr2ogr command-line, may use any output here, as long as
# the input is a GML file.
# TODO: find a way to use a GML-stream through stdin to ogr2ogr
[output_ogr2ogr]
class = outputs.execoutput.Ogr2OgrExecOutput
# destination format: OGR vector format name
dest_format = PostgreSQL
# destination datasource: name of datasource
dest_data_source = "PG:dbname={database} host={host} port={port} user={user} password={password} active_schema={schema}"
# layer creation options will only be added to ogr2ogr on first run
lco = -lco LAUNDER=YES -lco PRECISION=NO
# spatial_extent, translates to -spat xmin ymin xmax ymax
spatial_extent = {spatial_extent}
# gfs template
gfs_template = {gfs_template}
# miscellaneous ogr2ogr options
options = -append -gt 65536 {multi_opts} --config PG_USE_COPY NO --config CPL_ZIP_ENCODING CP437
	
# Below alternative outputs are meant for testing
# The ogr2ogr command-line, may use any output here, as long as
# the input is a GML file.
# TODO: find a way to use a GML-stream through stdin to ogr2ogr

# Output to GeoPackage File, will contain all Layers
[output_ogr2ogr_gpkg]
class = outputs.execoutput.Ogr2OgrExecOutput
# destination format: OGR vector format name
dest_format = GPKG
# destination datasource: path to .gpkg output file
dest_data_source = "{temp_dir}/output.gpkg"
# layer creation options will only be added to ogr2ogr on first run
lco = -lco SPATIAL_INDEX=YES -lco PRECISION=NO
# spatial_extent, translates to -spat xmin ymin xmax ymax
spatial_extent = {spatial_extent}
# gfs template
gfs_template = {gfs_template}
# miscellaneous ogr2ogr options
options = -append -gt 65536 {multi_opts} --config CPL_ZIP_ENCODING CP437


# Send to stdout
[output_std]
class = outputs.standardoutput.StandardOutput
