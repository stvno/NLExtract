# Example of process-chains for extracting Top10NL source data from GML to PostGIS.
# A Chain is a series of Components: one Input, zero or more Filters and one Output.
# The output of a Component is connected to the input of the next Component (except for
# the final Output Component, which writes to the final destination, e.g. Postgres.
#
# Currently 3 chains are executed in the following order:
# - SQL pre:  DB initialization, delete tables, create schema
# - Main ETL chain, consists of the following components
# 1. input_zip_file: reads files from input ZIP file(s)
# 2. extract_zip_file: extracts a GML file from a ZIP file
# 3. output_ogr2ogr: output using ogr2ogr, input is a transformed GML file, output can be any OGR output
# - SQL post:  remove duplicates
#
# Any substitutable values are specified in curly brackets e.g. {password}.
# Actual values can be passed as args to Stetl main.py or as arguments from a wrapper program
# like top10extract.py to etl.py. Here are the 3 chains:

[etl]
chains = input_sql_pre|schema_name_filter|output_postgres,
         input_zip_file|extract_zip_file|prepare_gfs|output_ogr2ogr,
         input_dummy_zip_file|extract_dummy_zip_file|output_ogr2ogr_init,
         input_sql_post|schema_name_filter|output_postgres

# Pre SQL file inputs to be executed
[input_sql_pre]
class = inputs.fileinput.StringFileInput
file_path = {projectetl}/sql/drop-tables-v1.2.sql,sql/create-schema.sql

# Post SQL file inputs to be executed
[input_sql_post]
class = inputs.fileinput.StringFileInput
file_path = {projectetl}/sql/create-final-tables-v1.2.sql,sql/update-multiattributes-v1.2.sql

# Generic filter to substitute Python-format string values like {schema} in string
[schema_name_filter]
class = filters.stringfilter.StringSubstitutionFilter
# format args {schema} is schema name
format_args = schema:{schema}

[output_postgres]
class = outputs.dboutput.PostgresDbOutput
database = {database}
host = {host}
port = {port}
user = {user}
password = {password}
schema = {schema}

# The source input ZIP-file(s) from dir, producing 'records' with ZIP file name and inner file names
[input_zip_file]
class=inputs.fileinput.ZipFileInput
file_path = {input_dir}
filename_pattern = *.[zZ][iI][pP]
name_filter=*.[gG][mM][lL]

# Filter to extract a ZIP file one by one to a temporary location
[extract_zip_file]
class=filters.zipfileextractor.ZipFileExtractor
file_path = {temp_dir}/fromzip-tmp.gml

# Prepare the generic GFS file to optimize the loading speed
[prepare_gfs]
class = stetlcomponents.gfspreparationfilter.GfsPreparationFilter
input_gfs = {gfs_template}

# The ogr2ogr command-line, may use any output here, as long as
# the input is a GML file. The "temp_file" is where etree-docs
# are saved. It has to be the same file as in the ogr2ogr command.
# TODO: find a way to use a GML-stream through stdin to ogr2ogr
[output_ogr2ogr]
class = outputs.execoutput.Ogr2OgrExecOutput
# destination format: OGR vector format name
dest_format = PostgreSQL
# destination datasource: name of datasource
dest_data_source = "PG:dbname={database} host={host} port={port} user={user} password={password} active_schema={schema}"
# layer creation options will only be added to ogr2ogr on first run
lco = -lco LAUNDER=YES -lco PRECISION=NO
# spatial_extent, translates to -spat xmin ymin xmax ymax
spatial_extent = {spatial_extent}
# gfs template
#gfs_template = {gfs_template}
# miscellaneous ogr2ogr options
options = -append -gt 65536 {multi_opts}
# cleanup input?
cleanup_input = True

[input_dummy_zip_file]
class=inputs.fileinput.ZipFileInput
file_path = data
filename_pattern = dummy.zip

[extract_dummy_zip_file]
class=filters.zipfileextractor.ZipFileExtractor
file_path = {temp_dir}/dummy.gml
delete_file = False

# Initialization of all tables with empty file
# Note that this is done _after_ loading all the data, since this way the ETL is much faster.
[output_ogr2ogr_init]
class = outputs.execoutput.Ogr2OgrExecOutput
dest_format = PostgreSQL
dest_data_source = "PG:dbname={database} host={host} port={port} user={user} password={password} active_schema={schema}"
gfs_template = {gfs_template}
options = -append -gt 65536 {multi_opts}
cleanup_input = True

# Validator for XML
[xml_schema_validator]
class = filters.xmlvalidator.XmlSchemaValidator
xsd = http://www.kadaster.nl/schemas/top10nl/vyyyymmdd/TOP10NL_1_2.xsd
enabled = False

# Below Alternative outputs for testing

# Send to stdout
[output_std]
class = outputs.standardoutput.StandardXmlOutput

[output_file]
class = outputs.fileoutput.FileOutput
file_path = test/output/top10nl-fc.gml

# Output multiple files ala Top10 file chunks GML
# Use numbering as in file expression.
[output_multifile]
class = outputs.fileoutput.MultiFileOutput
file_path = test/output/top10nl-%03d.gml

